{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Continous Values Using Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Artificial Intelligence - Final Computer Assginment\n",
    "> ### Shakiba Bolbolian Khah - 810196426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from scipy import stats\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Deleting Outliners**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteOutliners():\n",
    "    global df\n",
    "    df = df[((df['price'] == -1) | ((df['price'] > 40000) & (df['brand'] != 'Nokia::نوکیا')) |\n",
    "            ((df['price'] > 30000) & (df['brand'] == 'Nokia::نوکیا'))) & (df['price'] < 5000000)]\n",
    "#     z = np.abs(stats.zscore(df['price']))\n",
    "#     threshold = 3\n",
    "#     df = df[(z < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Handling Categorical Features (Label and One Hot Encoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeData(type):\n",
    "    global df\n",
    "    if type == 'Label':\n",
    "        labelencoder = LabelEncoder()\n",
    "        \n",
    "        df['brand cat'] = labelencoder.fit_transform(df['brand'])\n",
    "        df['city cat'] = labelencoder.fit_transform(df['city'])\n",
    "\n",
    "        global brandNames, cityNames\n",
    "        for i in range(len(df['brand'])): \n",
    "            brandNames[df.iloc[i]['brand cat']] = df.iloc[i]['brand']\n",
    "            cityNames[df.iloc[i]['city cat']] = df.iloc[i]['city']\n",
    "\n",
    "        df = df.drop(columns= ['city','brand'])\n",
    "        \n",
    "    elif type == 'one hot':\n",
    "        processedDf = pd.concat([df, pd.get_dummies(df['brand cat'])], axis=1)\n",
    "        processedDf = processedDf.rename(columns= brandNames)\n",
    "        processedDf = pd.concat([processedDf, pd.get_dummies(processedDf['city cat'])], axis=1)\n",
    "        processedDf = processedDf.rename(columns= cityNames)\n",
    "        processedDf = processedDf.drop(columns=['city cat', 'brand cat'])\n",
    "        return processedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Improving Persian Texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(string.punctuation) + ['گوشی','سلام','قیمت','تومان','تومن','موبایل','تلفن','همراه'\n",
    "                                        ,'فوری','تخفیف','عجله','ممنون']+ stopwords_list()\n",
    "\n",
    "def improvePersian(l):\n",
    "    newList = []\n",
    "    p = r'^[a-zA-Z0-9۱-۹]+'\n",
    "    for w in l:\n",
    "        if re.match(p, w) and not w.isnumeric():\n",
    "                newW = unidecode(str(w))\n",
    "                newList.append(newW.lower())\n",
    "#         elif w not in stopwords:\n",
    "#             newList.append(w)\n",
    "            \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Text Processing (Tokenizing, Stemming, Normalizing, etc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBrand(b):\n",
    "    return b.split(':')[0]\n",
    "       \n",
    "def stemData(l):\n",
    "    ps = PorterStemmer()\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "    t = []\n",
    "    for i in l:\n",
    "        t.append(ps.stem(i))\n",
    "    return t\n",
    "    \n",
    "def preprocessTexts():\n",
    "    global df\n",
    "    normalizer = Normalizer()\n",
    "    df['desc'] = df['desc'].apply(normalizer.affix_spacing)\n",
    "\n",
    "    tokenizer = WordTokenizer()\n",
    "    df['desc'] = df['desc'].apply(tokenizer.tokenize)\n",
    "    df['title'] = df['title'].apply(tokenizer.tokenize)\n",
    "    \n",
    "    df['title'] = df['title'].apply(improvePersian)\n",
    "    df['desc'] = df['desc'].apply(improvePersian)\n",
    "\n",
    "    df['brand'] = df['brand'].apply(extractBrand)\n",
    "    \n",
    "    df['desc'] = df['desc'].apply(stemData)\n",
    "    df['title'] = df['title'].apply(stemData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Date Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {}\n",
    "\n",
    "def preprocessDate():\n",
    "    def isWeekend(s):\n",
    "        weekDay = s.split()[0]\n",
    "        if weekDay=='Saturday' or weekDay == 'Friday':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['is weekend'] = df['created_at'].apply(isWeekend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Applying Preprocessors (part I)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./mobile_phone_dataset.csv', usecols = ['brand','city','title',\n",
    "                                                          'desc','image_count','created_at','price'])\n",
    "\n",
    "brandNames = {}\n",
    "cityNames = {}\n",
    "\n",
    "deleteOutliners()\n",
    "preprocessTexts()\n",
    "preprocessDate()\n",
    "df = df.drop(columns= ['created_at'])\n",
    "encodeData('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Calculating Correlation Between Different Price Column and Other Ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Apple', 1: 'HTC', 2: 'Huawei', 3: 'LG', 4: 'Lenovo', 5: 'Nokia', 6: 'Samsung', 7: 'Sony', 8: 'ZTE'}\n",
      "Correlation between brand and price: -0.2941200888869938\n"
     ]
    }
   ],
   "source": [
    "corr, _ = pearsonr(df['price'], df['brand cat'])\n",
    "print(brandNames)\n",
    "print(\"Correlation between brand and price:\", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Ahvaz', 1: 'Isfahan', 2: 'Karaj', 3: 'Kermanshah', 4: 'Mashhad', 5: 'Qom', 6: 'Shiraz', 7: 'Tabriz', 8: 'Tehran'}\n",
      "Correlation between city and price: 0.09134597090831476\n"
     ]
    }
   ],
   "source": [
    "corr, _ = pearsonr(df['price'], df['city cat'])\n",
    "print(cityNames)\n",
    "print(\"Correlation between city and price:\", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between weekend and price: -0.014327284995315989\n"
     ]
    }
   ],
   "source": [
    "corr, _ = pearsonr(df['price'], df['is weekend'])\n",
    "print(\"Correlation between weekend and price:\", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between image count and price: 0.02673846216780569\n"
     ]
    }
   ],
   "source": [
    "corr, _ = pearsonr(df['price'], df['image_count'])\n",
    "print(\"Correlation between image count and price:\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Applying Preprocessors (part II)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>price</th>\n",
       "      <th>Apple</th>\n",
       "      <th>HTC</th>\n",
       "      <th>Huawei</th>\n",
       "      <th>LG</th>\n",
       "      <th>Lenovo</th>\n",
       "      <th>Nokia</th>\n",
       "      <th>Samsung</th>\n",
       "      <th>...</th>\n",
       "      <th>Ahvaz</th>\n",
       "      <th>Isfahan</th>\n",
       "      <th>Karaj</th>\n",
       "      <th>Kermanshah</th>\n",
       "      <th>Mashhad</th>\n",
       "      <th>Qom</th>\n",
       "      <th>Shiraz</th>\n",
       "      <th>Tabriz</th>\n",
       "      <th>Tehran</th>\n",
       "      <th>text part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1150000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[j5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>590000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[j5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5s]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[5s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[galaxi, s5, gold]</td>\n",
       "      <td>[]</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[galaxi, s5, gold]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                title desc    price  Apple  HTC  Huawei  LG  Lenovo  Nokia  \\\n",
       "0                  []   []    60000      0    0       0   0       0      1   \n",
       "1                  []   []  1150000      1    0       0   0       0      0   \n",
       "2                [j5]   []   590000      0    0       0   0       0      0   \n",
       "3                [5s]   []  1100000      1    0       0   0       0      0   \n",
       "4  [galaxi, s5, gold]   []   900000      0    0       0   0       0      0   \n",
       "\n",
       "   Samsung  ...  Ahvaz  Isfahan  Karaj  Kermanshah  Mashhad  Qom  Shiraz  \\\n",
       "0        0  ...      0        0      0           0        0    1       0   \n",
       "1        0  ...      0        0      0           0        0    0       0   \n",
       "2        1  ...      0        0      0           0        1    0       0   \n",
       "3        0  ...      0        0      1           0        0    0       0   \n",
       "4        1  ...      0        0      0           0        0    0       0   \n",
       "\n",
       "   Tabriz  Tehran           text part  \n",
       "0       0       0                  []  \n",
       "1       0       1                  []  \n",
       "2       0       0                [j5]  \n",
       "3       0       0                [5s]  \n",
       "4       0       1  [galaxi, s5, gold]  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDF = encodeData('one hot')\n",
    "regressionDF['text part'] = regressionDF['title'] + regressionDF['desc']\n",
    "regressionDF = regressionDF.drop(columns = ['is weekend', 'image_count'])\n",
    "regressionDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Splitting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = regressionDF[regressionDF['price'] == -1]\n",
    "trainData = regressionDF[regressionDF['price'] != -1]\n",
    "randomState = 34\n",
    "y = trainData['price']\n",
    "X = trainData.drop(columns=['price', 'title', 'desc'])\n",
    "yPredict = testData['price']\n",
    "XPredict = testData.drop(columns=['price', 'title', 'desc'])\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.20, random_state= randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Constructing Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsBag = {}\n",
    "\n",
    "for i in XTrain['text part']:\n",
    "    for j in i:\n",
    "        if j in wordsBag:\n",
    "            wordsBag[j] += 1\n",
    "        else:\n",
    "            wordsBag[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remList = []\n",
    "for i in wordsBag:\n",
    "    num = wordsBag[i]\n",
    "    if num < 150  or num > 2500 or i.isnumeric():\n",
    "        remList.append(i)\n",
    "\n",
    "d = [wordsBag.pop(key) for key in remList]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Cheking Existance of Bag of Words Data in Each Row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleTexts(data):\n",
    "    wordAttr = {k: [] for k in wordsBag}\n",
    "\n",
    "    for t in data['text part']:\n",
    "        for w in wordsBag:\n",
    "            if w in t:\n",
    "                wordAttr[w].append(1)\n",
    "            else:\n",
    "                wordAttr[w].append(0)\n",
    "    return pd.DataFrame.from_dict(wordAttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDF(df1, df2):\n",
    "    df1.is_copy = False\n",
    "    df2.is_copy = False\n",
    "    df1.loc[:,'idx'] = list(range(len(df1)))\n",
    "    df2.loc[:,'idx'] = list(range(len(df2)))\n",
    "    mergedDF = pd.merge(left= df1, right= df2, left_on='idx', right_on='idx')\n",
    "    return mergedDF.drop(columns = ['idx', 'text part'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Evaluation Function (MSE & MAE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTestList = yTest.to_list()\n",
    "yTrainList = yTrain.to_list()\n",
    "yPredictIndex = list(yPredict.index)\n",
    "\n",
    "def evaluateModel(predict, real, dataType):\n",
    "    MSE = 0\n",
    "    MAE = 0\n",
    "    for i in range(len(predict)):\n",
    "        MSE += math.pow(predict[i] - real[i] , 2)\n",
    "        MAE += abs(predict[i] - real[i])\n",
    "\n",
    "    MSE /= len(predict)\n",
    "    MAE /= len(predict)\n",
    "    print('MSE value for '+ dataType + ' data :' + '%.2f'%MSE)\n",
    "    print('MAE value for '+ dataType + ' data :' + '%.2f'%MAE)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Writing Predictions in File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeInFile(predictDF):\n",
    "    output = pd.DataFrame(columns = ['index', 'price'])\n",
    "    \n",
    "    for i in range(len(predictDF)):\n",
    "        output = output.append({'index': yPredictIndex[i] , 'price': predictDF[i]}, ignore_index=True)\n",
    "    output.to_csv(r'./output.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **Model Construction, Training & Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of model: 0.5422\n",
      "-------------------------\n",
      "MSE value for test data :139992097758.22\n",
      "MAE value for test data :269497.34\n",
      "-------------------------\n",
      "MSE value for train data :138151570208.64\n",
      "MAE value for train data :268614.84\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "def trainTestPredictModel():\n",
    "    trainTextDF = handleTexts(XTrain)\n",
    "    XTrainFinal = mergeDF(XTrain, trainTextDF)\n",
    "    linearReg = LinearRegression()\n",
    "    reg = linearReg.fit(XTrainFinal, yTrain)\n",
    "    print('Score of model: %.4f' %reg.score(XTrainFinal, yTrain))\n",
    "    print('-------------------------')\n",
    "    \n",
    "    testTextDf = handleTexts(XTest)\n",
    "    XTestFinal = mergeDF(XTest, testTextDf)\n",
    "    yPredTest = reg.predict(XTestFinal)\n",
    "    evaluateModel(yPredTest, yTestList, 'test')\n",
    "    yPredTrain = reg.predict(XTrainFinal)\n",
    "    evaluateModel(yPredTrain, yTrainList, 'train')\n",
    "    \n",
    "    predictTextDf = handleTexts(XPredict)\n",
    "    XPredictFinal = mergeDF(XPredict, predictTextDf)\n",
    "    yPredictOutput = reg.predict(XPredictFinal)\n",
    "    writeInFile(yPredictOutput)\n",
    "        \n",
    "    \n",
    "trainTestPredictModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
